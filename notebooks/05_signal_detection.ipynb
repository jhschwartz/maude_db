{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety Signal Detection\n",
    "\n",
    "**Purpose**: Identify unusual patterns in adverse events  \n",
    "**Data**: 2020-2023 (4 years)  \n",
    "**Target Audience**: Advanced researchers, safety surveillance\n",
    "\n",
    "## What is Signal Detection?\n",
    "\n",
    "Signal detection identifies potential safety issues by looking for:\n",
    "- Sudden spikes in event counts\n",
    "- Changes in event type proportions\n",
    "- Emerging failure modes in narratives\n",
    "\n",
    "## Important Note\n",
    "\n",
    "This notebook demonstrates **exploratory techniques**. Statistical signals require clinical validation and proper epidemiological study design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent / 'src'))\n",
    "\n",
    "from maude_db import MaudeDatabase\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouping years by file for optimization...\n",
      "\n",
      "Downloading files...\n",
      "  Downloading device2020.zip...\n",
      "  Downloading device2021.zip...\n",
      "  Using cached device2022.zip\n",
      "  Using cached device2023.zip\n",
      "  WARNING: Expected file mdrfoithru2025.zip not available.\n",
      "  Using mdrfoithru2024.zip instead (latest available cumulative file).\n",
      "  Downloading mdrfoithru2024.zip...\n",
      "  Error downloading 2020: \n",
      "  Skipping master - download failed\n",
      "\n",
      "Processing data files...\n",
      "\n",
      "Loading device for year 2020...\n",
      "    Identified date columns: DATE_REMOVED_FLAG, IMPLANT_DATE_YEAR, DATE_REMOVED_YEAR, DATE_RECEIVED, EXPIRATION_DATE_OF_DEVICE, DATE_RETURNED_TO_MANUFACTURER\n",
      "    Processed 1,100,000 rows...\n",
      "    Total: 1,567,925 rows\n",
      "\n",
      "Loading device for year 2021...\n",
      "    Identified date columns: DATE_REMOVED_FLAG, IMPLANT_DATE_YEAR, DATE_REMOVED_YEAR, DATE_RECEIVED, EXPIRATION_DATE_OF_DEVICE, DATE_RETURNED_TO_MANUFACTURER\n",
      "    Processed 1,100,000 rows...\n",
      "    Processed 2,032,838 rows...\n",
      "    Total: 2,032,838 rows\n",
      "\n",
      "Loading device for year 2022...\n",
      "    Identified date columns: DATE_REMOVED_FLAG, IMPLANT_DATE_YEAR, DATE_REMOVED_YEAR, DATE_RECEIVED, EXPIRATION_DATE_OF_DEVICE, DATE_RETURNED_TO_MANUFACTURER\n",
      "    Processed 1,100,000 rows...\n",
      "    Processed 2,100,000 rows...\n",
      "    Total: 2,955,003 rows\n",
      "\n",
      "Loading device for year 2023...\n",
      "    Identified date columns: DATE_REMOVED_FLAG, IMPLANT_DATE_YEAR, DATE_REMOVED_YEAR, DATE_RECEIVED, EXPIRATION_DATE_OF_DEVICE, DATE_RETURNED_TO_MANUFACTURER\n",
      "    Processed 1,100,000 rows...\n",
      "    Processed 2,099,998 rows...\n",
      "    Total: 2,345,106 rows\n",
      "\n",
      "Loading master for years 2020-2023...\n",
      "    Processing cumulative file for years 2020-2023 (batch mode)...\n",
      "    Identified date columns: DATE_RECEIVED, DATE_REPORT, DATE_OF_EVENT, DATE_FACILITY_AWARE, REPORT_DATE, DATE_REPORT_TO_FDA, DATE_REPORT_TO_MANUFACTURER, DATE_MANUFACTURER_RECEIVED, DEVICE_DATE_OF_MANUFACTURE, DATE_ADDED, DATE_CHANGED, SUPPL_DATES_FDA_RECEIVED, SUPPL_DATES_MFR_RECEIVED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakeumms/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices /scripts/maude_db/src/maude_db/processors.py:255: ParserWarning: Skipping line 843808: Expected 86 fields in line 843808, saw 87\n",
      "\n",
      "  for i, chunk in enumerate(pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Scanned 1,099,999 rows, kept 1...\n",
      "    Scanned 2,099,999 rows, kept 1...\n",
      "    Scanned 3,099,999 rows, kept 471,816...\n",
      "    Scanned 4,099,999 rows, kept 1,471,392...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakeumms/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices /scripts/maude_db/src/maude_db/processors.py:255: ParserWarning: Skipping line 4432107: Expected 86 fields in line 4432107, saw 87\n",
      "\n",
      "  for i, chunk in enumerate(pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Scanned 5,099,998 rows, kept 2,471,026...\n",
      "    Scanned 6,099,998 rows, kept 3,470,651...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakeumms/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices /scripts/maude_db/src/maude_db/processors.py:255: ParserWarning: Skipping line 6128100: Expected 86 fields in line 6128100, saw 87\n",
      "\n",
      "  for i, chunk in enumerate(pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Scanned 7,099,997 rows, kept 4,470,398...\n",
      "    Scanned 8,099,997 rows, kept 5,470,343...\n",
      "    Scanned 9,099,997 rows, kept 6,470,338...\n",
      "    Scanned 10,099,997 rows, kept 7,470,336...\n",
      "    Scanned 11,099,997 rows, kept 8,470,335...\n",
      "    Scanned 12,099,997 rows, kept 8,878,787...\n",
      "    Scanned 13,099,997 rows, kept 8,878,788...\n",
      "    Scanned 14,099,997 rows, kept 8,878,788...\n",
      "    Scanned 15,099,997 rows, kept 8,878,789...\n",
      "    Scanned 16,099,997 rows, kept 8,878,790...\n",
      "    Scanned 17,099,997 rows, kept 8,878,790...\n",
      "    Scanned 18,099,997 rows, kept 8,878,790...\n",
      "    Scanned 19,099,997 rows, kept 8,878,790...\n",
      "    Scanned 20,099,997 rows, kept 8,878,790...\n",
      "    Total: Scanned 20,747,247 rows, loaded 8,878,790 rows for 4 years\n",
      "    Per-year breakdown:\n",
      "      2020: 1,564,999 rows\n",
      "      2021: 2,028,313 rows\n",
      "      2022: 2,945,665 rows\n",
      "      2023: 2,339,813 rows\n",
      "\n",
      "Creating indexes...\n",
      "\n",
      "Database update complete\n"
     ]
    }
   ],
   "source": [
    "db = MaudeDatabase('signal_detection.db', verbose=True)\n",
    "\n",
    "db.add_years(\n",
    "    years='2020-2023',\n",
    "    tables=['device', 'master'],\n",
    "    download=True,\n",
    "    data_dir='./maude_data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Temporal Analysis: Detect Spikes\n",
    "\n",
    "Look for months with unusually high event counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events: 827,623\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot assemble with duplicate keys",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal events: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Convert dates and group by month\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDATE_RECEIVED\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcoerce\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33myear_month\u001b[39m\u001b[33m'\u001b[39m] = results[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].dt.to_period(\u001b[33m'\u001b[39m\u001b[33mM\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m monthly = results.groupby(\u001b[33m'\u001b[39m\u001b[33myear_month\u001b[39m\u001b[33m'\u001b[39m).size()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices /.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1075\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m     result = \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[32m   1077\u001b[39m     cache_array = _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices /.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1170\u001b[39m, in \u001b[36m_assemble_from_unit_mappings\u001b[39m\u001b[34m(arg, errors, utc)\u001b[39m\n\u001b[32m   1168\u001b[39m arg = DataFrame(arg)\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arg.columns.is_unique:\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot assemble with duplicate keys\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1172\u001b[39m \u001b[38;5;66;03m# replace passed unit with _unit_map\u001b[39;00m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(value):\n",
      "\u001b[31mValueError\u001b[39m: cannot assemble with duplicate keys"
     ]
    }
   ],
   "source": [
    "# Query device of interest\n",
    "device_name = 'insulin pump'\n",
    "results = db.query_device(device_name=device_name)\n",
    "print(f\"Total events: {len(results):,}\")\n",
    "\n",
    "# Convert dates and group by month\n",
    "results['date'] = pd.to_datetime(results['DATE_RECEIVED'], errors='coerce')\n",
    "results['year_month'] = results['date'].dt.to_period('M')\n",
    "\n",
    "monthly = results.groupby('year_month').size()\n",
    "print(f\"\\nMonthly event counts:\")\n",
    "print(monthly.tail(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect spikes using statistical threshold\n",
    "mean = monthly.mean()\n",
    "std = monthly.std()\n",
    "threshold = mean + 2*std  # 2 standard deviations\n",
    "\n",
    "spikes = monthly[monthly > threshold]\n",
    "print(f\"\\nMonths exceeding threshold ({threshold:.0f} events):\")\n",
    "print(spikes)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(monthly.index.astype(str), monthly.values, marker='o', linewidth=2)\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.0f})')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Event Count')\n",
    "plt.title(f'{device_name.title()} Events Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Event Type Proportion Changes\n",
    "\n",
    "Detect if the ratio of deaths/injuries/malfunctions changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate event type proportions by year\n",
    "results['year'] = results['date'].dt.year\n",
    "\n",
    "yearly_breakdown = []\n",
    "for year in sorted(results['year'].dropna().unique()):\n",
    "    year_data = results[results['year'] == year]\n",
    "    breakdown = db.event_type_breakdown_for(year_data)\n",
    "    yearly_breakdown.append({\n",
    "        'Year': int(year),\n",
    "        'Total': breakdown['total'],\n",
    "        'Deaths': breakdown['deaths'],\n",
    "        'Injuries': breakdown['injuries'],\n",
    "        'Malfunctions': breakdown['malfunctions'],\n",
    "        'Death_Rate': breakdown['deaths'] / breakdown['total'] if breakdown['total'] > 0 else 0\n",
    "    })\n",
    "\n",
    "breakdown_df = pd.DataFrame(yearly_breakdown)\n",
    "print(breakdown_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limitations and Next Steps\n",
    "\n",
    "**Limitations of this analysis:**\n",
    "- No adjustment for market growth\n",
    "- Reporting bias (changes in reporting practices)\n",
    "- Seasonal effects not considered\n",
    "- Multiple testing (many comparisons)\n",
    "\n",
    "**For rigorous signal detection:**\n",
    "1. Use proper statistical methods (Poisson regression, disproportionality analysis)\n",
    "2. Adjust for confounders (market size, reporting trends)\n",
    "3. Validate signals clinically\n",
    "4. Consider recall/label changes as co-variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()\n",
    "print(\"\\nâœ“ Signal detection complete!\")\n",
    "print(\"See docs/research_guide.md for best practices.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
