{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helper Methods Reference\n",
        "\n",
        "**Purpose**: Complete API overview\n",
        "**Data**: 1998 + 2022\n",
        "\n",
        "Demonstrates all helper methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, str(Path().resolve().parent / 'src'))\n",
        "\n",
        "from pymaude import MaudeDatabase\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Grouping years by file for optimization...\n",
            "\n",
            "Downloading files...\n",
            "  Downloading device2001.zip...\n",
            "  Using cached device2022.zip\n",
            "  Using cached mdrfoithru2025.zip\n",
            "\n",
            "Processing data files...\n",
            "\n",
            "Loading device for year 2001...\n",
            "    Identified date columns: DATE_REMOVED_FLAG, IMPLANT_DATE_YEAR, DATE_REMOVED_YEAR, DATE_RECEIVED, EXPIRATION_DATE_OF_DEVICE, DATE_RETURNED_TO_MANUFACTURER\n",
            "    Total: 59,066 rows\n",
            "\n",
            "device for year 2022 already loaded and unchanged, skipping\n",
            "\n",
            "Loading master for years 2001-2022...\n",
            "  File changed, refreshing years: [2022]\n",
            "  Deleting old data for master year 2022...\n",
            "    Processing cumulative file for years 2001-2022 (batch mode)...\n",
            "    Identified date columns: DATE_RECEIVED, DATE_REPORT, DATE_OF_EVENT, DATE_FACILITY_AWARE, REPORT_DATE, DATE_REPORT_TO_FDA, DATE_REPORT_TO_MANUFACTURER, DATE_MANUFACTURER_RECEIVED, DEVICE_DATE_OF_MANUFACTURE, DATE_ADDED, DATE_CHANGED, SUPPL_DATES_FDA_RECEIVED, SUPPL_DATES_MFR_RECEIVED\n",
            "    Scanned 1,100,000 rows, kept 0...\n",
            "    Scanned 2,100,000 rows, kept 0...\n",
            "    Scanned 3,100,000 rows, kept 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jakeumms/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices/scripts/maude_db/src/maude_db/processors.py:283: ParserWarning: Skipping line 3732627: Expected 86 fields in line 3732627, saw 87\n",
            "\n",
            "  for i, chunk in enumerate(pd.read_csv(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Scanned 4,099,999 rows, kept 1...\n",
            "    Scanned 5,099,999 rows, kept 1...\n",
            "    Scanned 6,099,999 rows, kept 1...\n",
            "    Scanned 7,099,999 rows, kept 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jakeumms/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices/scripts/maude_db/src/maude_db/processors.py:283: ParserWarning: Skipping line 7320926: Expected 86 fields in line 7320926, saw 87\n",
            "\n",
            "  for i, chunk in enumerate(pd.read_csv(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Scanned 8,099,998 rows, kept 242,357...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jakeumms/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices/scripts/maude_db/src/maude_db/processors.py:283: ParserWarning: Skipping line 9016919: Expected 86 fields in line 9016919, saw 87\n",
            "\n",
            "  for i, chunk in enumerate(pd.read_csv(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Scanned 9,099,997 rows, kept 1,241,981...\n",
            "    Scanned 10,099,997 rows, kept 2,241,759...\n",
            "    Scanned 11,099,997 rows, kept 2,945,665...\n",
            "    Scanned 12,099,997 rows, kept 2,945,665...\n",
            "    Scanned 13,099,997 rows, kept 2,945,665...\n",
            "    Scanned 14,099,997 rows, kept 2,945,665...\n",
            "    Scanned 15,099,997 rows, kept 2,945,665...\n",
            "    Scanned 16,099,997 rows, kept 2,945,665...\n",
            "    Scanned 17,099,997 rows, kept 2,945,665...\n",
            "    Scanned 18,099,997 rows, kept 2,945,665...\n",
            "    Scanned 19,099,997 rows, kept 2,945,666...\n",
            "    Scanned 20,099,997 rows, kept 2,945,666...\n",
            "    Scanned 21,099,997 rows, kept 2,945,666...\n",
            "    Scanned 22,099,997 rows, kept 2,945,666...\n",
            "    Scanned 23,099,997 rows, kept 2,946,023...\n",
            "    Total: Scanned 23,636,064 rows, loaded 3,004,056 rows for 2 years\n",
            "    Per-year breakdown:\n",
            "      2001: 58,391 rows\n",
            "      2022: 2,945,665 rows\n",
            "\n",
            "Creating indexes...\n",
            "\n",
            "Database update complete\n"
          ]
        }
      ],
      "source": [
        "db = MaudeDatabase('getting_started.db', verbose=True)\n",
        "db.add_years(years=[2001, 2022], tables=['device', 'master'], download=True, data_dir='./maude_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results: 182,900 rows\n"
          ]
        }
      ],
      "source": [
        "# query_device() - primary helper\n",
        "results = db.query_device(device_name='catheter')\n",
        "print(f'Results: {len(results):,} rows')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'total': 182900, 'deaths': 4681, 'injuries': 52298, 'malfunctions': 125605, 'other': 57295}\n"
          ]
        }
      ],
      "source": [
        "# event_type_breakdown_for()\n",
        "breakdown = db.event_type_breakdown_for(results)\n",
        "print(breakdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           manufacturer  event_count\n",
            "0         BOSTON SCIENTIFIC CORPORATION        28478\n",
            "1  C.R. BARD, INC. (COVINGTON) -1018233        19161\n",
            "2    C.R. BARD, INC. (BASD) -3006260740        14471\n",
            "3                  EDWARDS LIFESCIENCES         9636\n",
            "4                  BIOSENSE WEBSTER INC         9351\n"
          ]
        }
      ],
      "source": [
        "# top_manufacturers_for()\n",
        "top = db.top_manufacturers_for(results, n=5)\n",
        "print(top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   year  event_count  deaths  injuries  malfunctions\n",
            "0  2001         3331      90      1342          1683\n",
            "1  2020        40673     964     11201         28492\n",
            "2  2021        43932    1029     11946         30940\n",
            "3  2022        45402    1074     12730         31575\n",
            "4  2023        49562    1524     15079         32915\n"
          ]
        }
      ],
      "source": [
        "# trends_for()\n",
        "trends = db.trends_for(results)\n",
        "print(trends)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "cannot assemble with duplicate keys",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# date_range_summary_for()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m date_info = \u001b[43mdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate_range_summary_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(date_info)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices/scripts/maude_db/src/maude_db/database.py:1443\u001b[39m, in \u001b[36mMaudeDatabase.date_range_summary_for\u001b[39m\u001b[34m(self, results_df)\u001b[39m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mDATE_RECEIVED\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m results_df.columns:\n\u001b[32m   1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataFrame must contain \u001b[39m\u001b[33m'\u001b[39m\u001b[33mDATE_RECEIVED\u001b[39m\u001b[33m'\u001b[39m\u001b[33m column\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m dates = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDATE_RECEIVED\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m first = dates.min()\n\u001b[32m   1445\u001b[39m last = dates.max()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices/.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1075\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m     result = \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[32m   1077\u001b[39m     cache_array = _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/University of Michigan Dropbox/Jacob Schwartz/eras reserach projects/MAUDE thrombectomy devices/.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1170\u001b[39m, in \u001b[36m_assemble_from_unit_mappings\u001b[39m\u001b[34m(arg, errors, utc)\u001b[39m\n\u001b[32m   1168\u001b[39m arg = DataFrame(arg)\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arg.columns.is_unique:\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot assemble with duplicate keys\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1172\u001b[39m \u001b[38;5;66;03m# replace passed unit with _unit_map\u001b[39;00m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(value):\n",
            "\u001b[31mValueError\u001b[39m: cannot assemble with duplicate keys"
          ]
        }
      ],
      "source": [
        "# date_range_summary_for()\n",
        "date_info = db.date_range_summary_for(results)\n",
        "print(date_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "db.close()\n",
        "print('âœ“ See docs/api_reference.md for complete docs!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
